{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k_nearest_neighbors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d40XUX6Tu6PF"
      },
      "source": [
        "# K Nearest Neighbors\n",
        "\n",
        "Esse notebook contém a implementação do algoritmo de aprendizado de máquina K Nearest Neighbors e sua aplicação no conjunto de dados clássico da Iris."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alSI7YQppVhQ",
        "outputId": "8e3278b6-20b2-4989-828f-b684359276e0"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "pprint(iris)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'DESCR': '.. _iris_dataset:\\n'\n",
            "          '\\n'\n",
            "          'Iris plants dataset\\n'\n",
            "          '--------------------\\n'\n",
            "          '\\n'\n",
            "          '**Data Set Characteristics:**\\n'\n",
            "          '\\n'\n",
            "          '    :Number of Instances: 150 (50 in each of three classes)\\n'\n",
            "          '    :Number of Attributes: 4 numeric, predictive attributes and the '\n",
            "          'class\\n'\n",
            "          '    :Attribute Information:\\n'\n",
            "          '        - sepal length in cm\\n'\n",
            "          '        - sepal width in cm\\n'\n",
            "          '        - petal length in cm\\n'\n",
            "          '        - petal width in cm\\n'\n",
            "          '        - class:\\n'\n",
            "          '                - Iris-Setosa\\n'\n",
            "          '                - Iris-Versicolour\\n'\n",
            "          '                - Iris-Virginica\\n'\n",
            "          '                \\n'\n",
            "          '    :Summary Statistics:\\n'\n",
            "          '\\n'\n",
            "          '    ============== ==== ==== ======= ===== ====================\\n'\n",
            "          '                    Min  Max   Mean    SD   Class Correlation\\n'\n",
            "          '    ============== ==== ==== ======= ===== ====================\\n'\n",
            "          '    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n'\n",
            "          '    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n'\n",
            "          '    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n'\n",
            "          '    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n'\n",
            "          '    ============== ==== ==== ======= ===== ====================\\n'\n",
            "          '\\n'\n",
            "          '    :Missing Attribute Values: None\\n'\n",
            "          '    :Class Distribution: 33.3% for each of 3 classes.\\n'\n",
            "          '    :Creator: R.A. Fisher\\n'\n",
            "          '    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n'\n",
            "          '    :Date: July, 1988\\n'\n",
            "          '\\n'\n",
            "          'The famous Iris database, first used by Sir R.A. Fisher. The '\n",
            "          'dataset is taken\\n'\n",
            "          \"from Fisher's paper. Note that it's the same as in R, but not as in \"\n",
            "          'the UCI\\n'\n",
            "          'Machine Learning Repository, which has two wrong data points.\\n'\n",
            "          '\\n'\n",
            "          'This is perhaps the best known database to be found in the\\n'\n",
            "          \"pattern recognition literature.  Fisher's paper is a classic in the \"\n",
            "          'field and\\n'\n",
            "          'is referenced frequently to this day.  (See Duda & Hart, for '\n",
            "          'example.)  The\\n'\n",
            "          'data set contains 3 classes of 50 instances each, where each class '\n",
            "          'refers to a\\n'\n",
            "          'type of iris plant.  One class is linearly separable from the other '\n",
            "          '2; the\\n'\n",
            "          'latter are NOT linearly separable from each other.\\n'\n",
            "          '\\n'\n",
            "          '.. topic:: References\\n'\n",
            "          '\\n'\n",
            "          '   - Fisher, R.A. \"The use of multiple measurements in taxonomic '\n",
            "          'problems\"\\n'\n",
            "          '     Annual Eugenics, 7, Part II, 179-188 (1936); also in '\n",
            "          '\"Contributions to\\n'\n",
            "          '     Mathematical Statistics\" (John Wiley, NY, 1950).\\n'\n",
            "          '   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and '\n",
            "          'Scene Analysis.\\n'\n",
            "          '     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page '\n",
            "          '218.\\n'\n",
            "          '   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New '\n",
            "          'System\\n'\n",
            "          '     Structure and Classification Rule for Recognition in Partially '\n",
            "          'Exposed\\n'\n",
            "          '     Environments\".  IEEE Transactions on Pattern Analysis and '\n",
            "          'Machine\\n'\n",
            "          '     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n'\n",
            "          '   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE '\n",
            "          'Transactions\\n'\n",
            "          '     on Information Theory, May 1972, 431-433.\\n'\n",
            "          '   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s '\n",
            "          'AUTOCLASS II\\n'\n",
            "          '     conceptual clustering system finds 3 classes in the data.\\n'\n",
            "          '   - Many, many more ...',\n",
            " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.6, 1.4, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]),\n",
            " 'feature_names': ['sepal length (cm)',\n",
            "                   'sepal width (cm)',\n",
            "                   'petal length (cm)',\n",
            "                   'petal width (cm)'],\n",
            " 'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/iris.csv',\n",
            " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
            " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2Ey9MSAqCo4",
        "outputId": "65294113-a257-4c92-d519-3dd5bf82c79f"
      },
      "source": [
        "import numpy as np\n",
        "from bisect import bisect\n",
        "from statistics import mode\n",
        "\n",
        "\n",
        "def k_nearest_neighbors(k, sample, data, targets):\n",
        "    # Neighbors contains a list of indexes sorted by distance from the sample\n",
        "    neighbors = list()\n",
        "    distances = list()\n",
        "\n",
        "    # Get distance for each neighbor\n",
        "    for index, neighbor in enumerate(data):\n",
        "        distance = 0\n",
        "\n",
        "        for feature in range(len(neighbor)):\n",
        "            distance += (neighbor[feature] - sample[feature]) ** 2 \n",
        "        \n",
        "        # Get position to insert sorted by distance in list\n",
        "        distance = np.sqrt(distance)\n",
        "        position = bisect(distances, distance)\n",
        "\n",
        "        # Insert distance and neighbor in position\n",
        "        distances.insert(position, distance)\n",
        "        neighbors.insert(position, index)\n",
        "    \n",
        "    nearest_neighbors = list()\n",
        "    \n",
        "    # Get the targets for k nearest neighbors\n",
        "    for index in range(k):\n",
        "        point_index = neighbors[index]\n",
        "        target = targets[point_index]\n",
        "\n",
        "        nearest_neighbors.append(target)\n",
        "    \n",
        "    # Mode of targets is the predicted class\n",
        "    return mode(nearest_neighbors)\n",
        "\n",
        "\n",
        "data = iris[\"data\"]\n",
        "targets = iris[\"target\"]\n",
        "sample = [7.9, 3.8, 6.4, 2. ]\n",
        "k = 5\n",
        "\n",
        "prediction = k_nearest_neighbors(k, sample, data, targets)\n",
        "prediction"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}